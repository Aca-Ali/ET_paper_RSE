{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd63f043-4dc5-4ce7-b442-2e5298e9003d",
   "metadata": {},
   "source": [
    "This notebook aims to filter poor quality data to prepare data for actual evapotranspiration estimation from eddy covariance data and also filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced267c-cae5-41cd-ba7b-90b41b616935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import iqr\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acde75d9-433d-4204-a859-e48bf28c7644",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f0805-21c9-446d-8530-8663492534e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement energy balance correction for hlaf hourly data and see the results\n",
    "def EBC_half_hourly_data(half_hourly_filtered_df,\n",
    "                         flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'}):\n",
    "\n",
    "   # Ensure index is in datetime format\n",
    "    df = half_hourly_filtered_df\n",
    "    df = df.sort_index()\n",
    "    df['hour'] = df.index.hour\n",
    "    df['minute'] = df.index.minute\n",
    "    df['time_of_day'] = df['hour'] + df['minute'] / 60  # Convert to decimal hour\n",
    "\n",
    "    # Step 1: Compute EBC_CF for all half-hourly values\n",
    "    df['EBC_CF'] = (df[flux_cols_dict['Rn']] - df[flux_cols_dict['G']]) / (df[flux_cols_dict['H']] + df[flux_cols_dict['LE']])\n",
    "\n",
    "    # Step 2: Remove Outliers (Beyond 1.5× IQR)\n",
    "    Q1, Q3 = df['EBC_CF'].quantile([0.25, 0.75])\n",
    "    IQR_value = Q3 - Q1\n",
    "    df['EBC_CF'] = np.where(\n",
    "        (df['EBC_CF'] < (Q1 - 1.5 * IQR_value)) | (df['EBC_CF'] > (Q3 + 1.5 * IQR_value)),\n",
    "        np.nan,\n",
    "        df['EBC_CF']\n",
    "    )\n",
    "    \n",
    "    # Step 3: Compute Smoothed EBC_CF Over ±15 Days for Each Half-Hour Time Step (Method 1)\n",
    "    def compute_EBC_CF_Method1(timestamp):\n",
    "        \n",
    "        \"\"\"Computes median of values within ±15-day window, filtering between 10:00-14:30 and 22:00-02:30.\"\"\"\n",
    "        df_window = df.loc[timestamp - pd.Timedelta(days=15) : timestamp + pd.Timedelta(days=15)]\n",
    "\n",
    "        # Select values in the two time ranges\n",
    "        valid_values = pd.concat([\n",
    "            df_window.between_time(\"10:00\", \"14:30\"),\n",
    "            df_window.between_time(\"22:00\", \"02:30\")\n",
    "        ])[\"EBC_CF\"].dropna()\n",
    "\n",
    "        return valid_values.median() if len(valid_values) >= 5 else np.nan\n",
    "    \n",
    "    df[\"EBC_CF_Method1\"] = df.index.to_series().apply(compute_EBC_CF_Method1)\n",
    "\n",
    "    # Step 4: Use Method 2 when \"EBC_CF_Method1\" is np.nan\n",
    "    def compute_EBC_CF_Method2(timestamp):\n",
    "        \"\"\" Function to compute Method 2 where Method 1 fails\"\"\"\n",
    "        return (df.loc[timestamp - pd.Timedelta(days=5) : timestamp + pd.Timedelta(days=5)]\n",
    "                  .between_time(\"10:00\", \"14:30\")\n",
    "                  .between_time((timestamp - pd.Timedelta(hours=1)).strftime(\"%H:%M\"),\n",
    "                                (timestamp + pd.Timedelta(hours=1)).strftime(\"%H:%M\"))[\"EBC_CF\"]\n",
    "                  .dropna()\n",
    "                  .mean() if len(df) >= 5 else np.nan)\n",
    "\n",
    "    df[\"EBC_CF_Method2\"] = df[df[\"EBC_CF_Method1\"].isna()].index.to_series().apply(compute_EBC_CF_Method2)\n",
    "    \n",
    "    # Step 5: Final EBC_CF selection: Use Method 1 where available, otherwise use Method 2\n",
    "    df[\"EBC_CF_Final\"] = df[\"EBC_CF_Method1\"].combine_first(df[\"EBC_CF_Method2\"])\n",
    "    \n",
    "    # Step 6: Apply the Corrected EBC_CF to All Data Points\n",
    "    df['H_corr'] = df[flux_cols_dict['H']] * df['EBC_CF_Final']\n",
    "    df['LE_corr'] = df[flux_cols_dict['LE']] * df['EBC_CF_Final']\n",
    "\n",
    "    # Compute Corrected Energy Imbalance (Should be Close to Zero)\n",
    "    df['Imb_corr'] = df[flux_cols_dict['Rn']] - df[flux_cols_dict['G']] - (df['H_corr'] + df['LE_corr'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a821c-541e-4214-8e67-42587b7a3de8",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b6356-c170-48cd-a997-b49c047f553d",
   "metadata": {},
   "source": [
    "#### Preprocess half hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f39e18-cbb9-461a-a60a-0413a452a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the half hourly data for all the seasons (3 towers with 9 seasons). The data can be downloaded from Ameriflux website!\n",
    "USUC1_path = os.path.join(os.getcwd(), 'AMF_US-UC1_BASE_HH_5-5.csv')\n",
    "USUC2_path = os.path.join(os.getcwd(), 'AMF_US-UC2_BASE_HH_5-5.csv')\n",
    "USHWB_path = os.path.join(os.getcwd(), 'AMF_US-HWB_BASE_HH_2-5.csv')\n",
    "\n",
    "USUC1_df = pd.read_csv(USUC1_path,skiprows=[0,1] ,index_col = 'TIMESTAMP_START', parse_dates=['TIMESTAMP_START'])\n",
    "USUC2_df = pd.read_csv(USUC2_path,skiprows=[0,1] ,index_col = 'TIMESTAMP_START', parse_dates=['TIMESTAMP_START'])\n",
    "USHWB_df = pd.read_csv(USHWB_path,skiprows=[0,1] ,index_col = 'TIMESTAMP_START', parse_dates=['TIMESTAMP_START'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca239aa-aaed-44a9-a0ed-232d7b976d6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adadkhah\\AppData\\Local\\Temp\\ipykernel_17324\\4133567684.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  USUC1_df_LE_filtered_2019.replace(-9999, np.nan, inplace=True)\n",
      "C:\\Users\\adadkhah\\AppData\\Local\\Temp\\ipykernel_17324\\4133567684.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  USUC1_df_LE_filtered_2020.replace(-9999, np.nan, inplace=True)\n",
      "C:\\Users\\adadkhah\\AppData\\Local\\Temp\\ipykernel_17324\\4133567684.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  USUC1_df_LE_filtered_2021.replace(-9999, np.nan, inplace=True)\n",
      "C:\\Users\\adadkhah\\AppData\\Local\\Temp\\ipykernel_17324\\4133567684.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  USUC1_df_LE_filtered_2022.replace(-9999, np.nan, inplace=True)\n",
      "C:\\Users\\adadkhah\\AppData\\Local\\Temp\\ipykernel_17324\\4133567684.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  USUC1_df_LE_filtered_2024.replace(-9999, np.nan, inplace=True)\n",
      "C:\\Users\\adadkhah\\AppData\\Local\\Temp\\ipykernel_17324\\4133567684.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  USUC2_df_LE_filtered_2019.replace(-9999, np.nan, inplace=True)\n",
      "C:\\Users\\adadkhah\\AppData\\Local\\Temp\\ipykernel_17324\\4133567684.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  USUC2_df_LE_filtered_2020.replace(-9999, np.nan, inplace=True)\n",
      "C:\\Users\\adadkhah\\AppData\\Local\\Temp\\ipykernel_17324\\4133567684.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  USUC2_df_LE_filtered_2021.replace(-9999, np.nan, inplace=True)\n",
      "C:\\Users\\adadkhah\\AppData\\Local\\Temp\\ipykernel_17324\\4133567684.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  USUC2_df_LE_filtered_2022.replace(-9999, np.nan, inplace=True)\n",
      "C:\\Users\\adadkhah\\AppData\\Local\\Temp\\ipykernel_17324\\4133567684.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  USUC2_df_LE_filtered_2024.replace(-9999, np.nan, inplace=True)\n",
      "C:\\Users\\adadkhah\\AppData\\Local\\Temp\\ipykernel_17324\\4133567684.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  USHWB_df_LE_filtered_2017.replace(-9999, np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# for each half hourly data check the flags and drop those rows with LE flag of 2\n",
    "Rn_col = 'NETRAD_1_1_1'\n",
    "LE_col = 'LE'\n",
    "H_col = 'H'\n",
    "LE_QC_flag_col = 'LE_SSITC_TEST'\n",
    "H_QC_flag_col = 'H_SSITC_TEST'\n",
    "\n",
    "# keep only LE values when both LE and H flags are not 2\n",
    "USUC1_df[LE_col] = USUC1_df.apply(lambda row: row[LE_col] if (row[LE_QC_flag_col]==0) & (row[H_QC_flag_col]==0) else np.nan, axis=1)\n",
    "USUC2_df[LE_col] = USUC2_df.apply(lambda row: row[LE_col] if (row[LE_QC_flag_col]==0) & (row[H_QC_flag_col]==0) else np.nan, axis=1)\n",
    "USHWB_df[LE_col] = USHWB_df.apply(lambda row: row[LE_col] if (row[LE_QC_flag_col]==0) & (row[H_QC_flag_col]==0) else np.nan, axis=1)\n",
    "\n",
    "# keep only H values when both LE and H flags are not 2\n",
    "USUC1_df[H_col] = USUC1_df.apply(lambda row: row[H_col] if (row[LE_QC_flag_col]==0) & (row[H_QC_flag_col]==0) else np.nan, axis=1)\n",
    "USUC2_df[H_col] = USUC2_df.apply(lambda row: row[H_col] if (row[LE_QC_flag_col]==0) & (row[H_QC_flag_col]==0) else np.nan, axis=1)\n",
    "USHWB_df[H_col] = USHWB_df.apply(lambda row: row[H_col] if (row[LE_QC_flag_col]==0) & (row[H_QC_flag_col]==0) else np.nan, axis=1)\n",
    "\n",
    "# filter negative LE during daylight\n",
    "USUC1_df[LE_col] = USUC1_df.apply(lambda row: np.nan if (row[Rn_col]>0) & (row[LE_col]<0) else row[LE_col], axis=1)\n",
    "USUC2_df[LE_col] = USUC2_df.apply(lambda row: np.nan if (row[Rn_col]>0) & (row[LE_col]<0) else row[LE_col], axis=1)\n",
    "USHWB_df[LE_col] = USHWB_df.apply(lambda row: np.nan if (row[Rn_col]>0) & (row[LE_col]<0) else row[LE_col], axis=1)\n",
    "\n",
    "# now divide the data into growing seasons and only keep the growing season period with 15 days of buffer for energy balance correction steps\n",
    "# Define the time windows for growing seasons\n",
    "US_UC_growing_season_2019 = [('2019-05-20', '2019-09-11')]\n",
    "US_UC_growing_season_2020 = [('2020-05-27', '2020-09-25')]\n",
    "US_UC_growing_season_2021 = [('2021-05-20', '2021-11-16')]\n",
    "US_UC_growing_season_2022 = [('2022-06-08', '2022-12-08')]\n",
    "US_UC_growing_season_2024 = [('2024-05-25', '2024-10-08')] \n",
    "US_HWB_growing_season_2017 = [('2017-04-15', '2017-09-30')]\n",
    "\n",
    "def filter_time_periods(df, time_periods, buffer_days=15):\n",
    "    buffer = pd.Timedelta(days=buffer_days)\n",
    "    return df.loc[pd.Timestamp(time_periods[0][0]) - buffer : pd.Timestamp(time_periods[0][1]) + buffer]\n",
    "\n",
    "USUC1_df_LE_filtered_2019 = filter_time_periods(USUC1_df, US_UC_growing_season_2019)\n",
    "USUC1_df_LE_filtered_2020 = filter_time_periods(USUC1_df, US_UC_growing_season_2020)\n",
    "USUC1_df_LE_filtered_2021 = filter_time_periods(USUC1_df, US_UC_growing_season_2021)\n",
    "USUC1_df_LE_filtered_2022 = filter_time_periods(USUC1_df, US_UC_growing_season_2022)\n",
    "USUC1_df_LE_filtered_2024 = filter_time_periods(USUC1_df, US_UC_growing_season_2024)\n",
    "\n",
    "USUC2_df_LE_filtered_2019 = filter_time_periods(USUC2_df, US_UC_growing_season_2019)\n",
    "USUC2_df_LE_filtered_2020 = filter_time_periods(USUC2_df, US_UC_growing_season_2020)\n",
    "USUC2_df_LE_filtered_2021 = filter_time_periods(USUC2_df, US_UC_growing_season_2021)\n",
    "USUC2_df_LE_filtered_2022 = filter_time_periods(USUC2_df, US_UC_growing_season_2022)\n",
    "USUC2_df_LE_filtered_2024 = filter_time_periods(USUC2_df, US_UC_growing_season_2024)\n",
    "\n",
    "USHWB_df_LE_filtered_2017 = filter_time_periods(USHWB_df, US_HWB_growing_season_2017)\n",
    "\n",
    "\n",
    "# Replace all -9999 with np.nan values\n",
    "USUC1_df_LE_filtered_2019.replace(-9999, np.nan, inplace=True)\n",
    "USUC1_df_LE_filtered_2020.replace(-9999, np.nan, inplace=True)\n",
    "USUC1_df_LE_filtered_2021.replace(-9999, np.nan, inplace=True)\n",
    "USUC1_df_LE_filtered_2022.replace(-9999, np.nan, inplace=True)\n",
    "USUC1_df_LE_filtered_2024.replace(-9999, np.nan, inplace=True)\n",
    "\n",
    "USUC2_df_LE_filtered_2019.replace(-9999, np.nan, inplace=True)\n",
    "USUC2_df_LE_filtered_2020.replace(-9999, np.nan, inplace=True)\n",
    "USUC2_df_LE_filtered_2021.replace(-9999, np.nan, inplace=True)\n",
    "USUC2_df_LE_filtered_2022.replace(-9999, np.nan, inplace=True)\n",
    "USUC2_df_LE_filtered_2024.replace(-9999, np.nan, inplace=True)\n",
    "\n",
    "USHWB_df_LE_filtered_2017.replace(-9999, np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bfa3a-e3e6-4912-9d76-e13538f2dedb",
   "metadata": {},
   "source": [
    "#### Half Hourly EB correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31278c40-d296-4747-8d30-8cc02c4ae66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform energy balance correction on half hourly values of LE and H\n",
    "USUC1_df_2019_LE_H_Corrected = EBC_half_hourly_data(USUC1_df_LE_filtered_2019,\n",
    "                                                       flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'})\n",
    "USUC1_df_2020_LE_H_Corrected = EBC_half_hourly_data(USUC1_df_LE_filtered_2020,\n",
    "                                                       flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'})\n",
    "USUC1_df_2021_LE_H_Corrected = EBC_half_hourly_data(USUC1_df_LE_filtered_2021,\n",
    "                                                       flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'})\n",
    "USUC1_df_2022_LE_H_Corrected = EBC_half_hourly_data(USUC1_df_LE_filtered_2022,\n",
    "                                                       flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'})\n",
    "\n",
    "USUC1_df_2024_LE_H_Corrected = EBC_half_hourly_data(USUC1_df_LE_filtered_2024,\n",
    "                                                       flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'})\n",
    "\n",
    "USUC2_df_2019_LE_H_Corrected = EBC_half_hourly_data(USUC2_df_LE_filtered_2019,\n",
    "                                                       flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'})\n",
    "USUC2_df_2020_LE_H_Corrected = EBC_half_hourly_data(USUC2_df_LE_filtered_2020,\n",
    "                                                       flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'})\n",
    "USUC2_df_2021_LE_H_Corrected = EBC_half_hourly_data(USUC2_df_LE_filtered_2021,\n",
    "                                                       flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'})\n",
    "USUC2_df_2022_LE_H_Corrected = EBC_half_hourly_data(USUC2_df_LE_filtered_2022,\n",
    "                                                       flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'})\n",
    "USUC2_df_2024_LE_H_Corrected = EBC_half_hourly_data(USUC2_df_LE_filtered_2024,\n",
    "                                                       flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'})\n",
    "\n",
    "USHWB_df_2017_LE_H_Corrected = EBC_half_hourly_data(USHWB_df_LE_filtered_2017,\n",
    "                                                       flux_cols_dict={'Rn':'NETRAD_1_1_1', 'G':'G_1_1_1','LE':'LE', 'H':'H'})\n",
    "\n",
    "\n",
    "# only keep daylight hours based on Rn>0 (6 am to 6:30 pm based on local time)\n",
    "USUC1_df_LE_filtered_2019_daylight = USUC1_df_2019_LE_H_Corrected.between_time(\"06:00\", \"18:30\")\n",
    "USUC1_df_LE_filtered_2020_daylight = USUC1_df_2020_LE_H_Corrected.between_time(\"06:00\", \"18:30\")\n",
    "USUC1_df_LE_filtered_2021_daylight = USUC1_df_2021_LE_H_Corrected.between_time(\"06:00\", \"18:30\")\n",
    "USUC1_df_LE_filtered_2022_daylight = USUC1_df_2022_LE_H_Corrected.between_time(\"06:00\", \"18:30\")\n",
    "USUC1_df_LE_filtered_2024_daylight = USUC1_df_2024_LE_H_Corrected.between_time(\"06:00\", \"18:30\")\n",
    "\n",
    "USUC2_df_LE_filtered_2019_daylight = USUC2_df_2019_LE_H_Corrected.between_time(\"06:00\", \"18:30\")\n",
    "USUC2_df_LE_filtered_2020_daylight = USUC2_df_2020_LE_H_Corrected.between_time(\"06:00\", \"18:30\")\n",
    "USUC2_df_LE_filtered_2021_daylight = USUC2_df_2021_LE_H_Corrected.between_time(\"06:00\", \"18:30\")\n",
    "USUC2_df_LE_filtered_2022_daylight = USUC2_df_2022_LE_H_Corrected.between_time(\"06:00\", \"18:30\")\n",
    "USUC2_df_LE_filtered_2024_daylight = USUC2_df_2024_LE_H_Corrected.between_time(\"06:00\", \"18:30\")\n",
    "\n",
    "USHWB_df_LE_filtered_2017_daylight = USHWB_df_2017_LE_H_Corrected.between_time(\"06:00\", \"18:30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1a6b888-88c5-4401-a803-8f8814757f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate data to hourly values and only keep columns that are helpful for evapotranspiration calculation/prediction\n",
    "agg_funcs = {\n",
    "    'LE_corr':'mean',\n",
    "    'TA_1_1_1':'mean',\n",
    "    'RH_1_1_1':'mean',\n",
    "    'SW_IN_1_1_1':'mean',\n",
    "    'LW_IN_1_1_1':'mean',\n",
    "    'WS':'mean',\n",
    "    'PA':'mean',\n",
    "    'P_RAIN_1_1_1':'sum'   \n",
    "}\n",
    "\n",
    "# only keep columns that are going to be used for the model training\n",
    "Columns_to_keep = ['LE_corr', 'TA_1_1_1', 'RH_1_1_1', 'SW_IN_1_1_1',  'LW_IN_1_1_1','WS', 'PA', 'P_RAIN_1_1_1']\n",
    "\n",
    "USUC1_df_processed_2019 = USUC1_df_LE_filtered_2019_daylight[Columns_to_keep].resample('h').agg(agg_funcs)\n",
    "USUC1_df_processed_2020 = USUC1_df_LE_filtered_2020_daylight[Columns_to_keep].resample('h').agg(agg_funcs)\n",
    "USUC1_df_processed_2021 = USUC1_df_LE_filtered_2021_daylight[Columns_to_keep].resample('h').agg(agg_funcs)\n",
    "USUC1_df_processed_2022 = USUC1_df_LE_filtered_2022_daylight[Columns_to_keep].resample('h').agg(agg_funcs)\n",
    "USUC1_df_processed_2024 = USUC1_df_LE_filtered_2024_daylight[Columns_to_keep].resample('h').agg(agg_funcs)\n",
    "\n",
    "USUC2_df_processed_2019 = USUC2_df_LE_filtered_2019_daylight[Columns_to_keep].resample('h').agg(agg_funcs)\n",
    "USUC2_df_processed_2020 = USUC2_df_LE_filtered_2020_daylight[Columns_to_keep].resample('h').agg(agg_funcs)\n",
    "USUC2_df_processed_2021 = USUC2_df_LE_filtered_2021_daylight[Columns_to_keep].resample('h').agg(agg_funcs)\n",
    "USUC2_df_processed_2022 = USUC2_df_LE_filtered_2022_daylight[Columns_to_keep].resample('h').agg(agg_funcs)\n",
    "USUC2_df_processed_2024 = USUC2_df_LE_filtered_2024_daylight[Columns_to_keep].resample('h').agg(agg_funcs)\n",
    "\n",
    "USHWB_df_processed_2017 = USHWB_df_LE_filtered_2017_daylight[Columns_to_keep].resample('h').agg(agg_funcs)\n",
    "\n",
    "\n",
    "# Now calculate ETa following the method of Harrison, L.P. 1963\n",
    "TA_col = 'TA_1_1_1' # air temperature column\n",
    "LE_col = 'LE_corr' # latent heat flux column\n",
    "\n",
    "def calculate_hourly_ETa(processed_df, LE_column=LE_col, TA_column=TA_col):\n",
    "    df = copy.deepcopy(processed_df)\n",
    "    df['ETa_corr'] = (df[LE_col] * 60 * 60) / ((2.501 - 0.002361 * df[TA_col]) * 10**6)\n",
    "    return df.drop([LE_col], axis=1)\n",
    "\n",
    "USUC1_df_processed_2019_ETa = calculate_hourly_ETa(USUC1_df_processed_2019)\n",
    "USUC1_df_processed_2020_ETa = calculate_hourly_ETa(USUC1_df_processed_2020)\n",
    "USUC1_df_processed_2021_ETa = calculate_hourly_ETa(USUC1_df_processed_2021)\n",
    "USUC1_df_processed_2022_ETa = calculate_hourly_ETa(USUC1_df_processed_2022)\n",
    "USUC1_df_processed_2024_ETa = calculate_hourly_ETa(USUC1_df_processed_2024)\n",
    "\n",
    "USUC2_df_processed_2019_ETa = calculate_hourly_ETa(USUC2_df_processed_2019)\n",
    "USUC2_df_processed_2020_ETa = calculate_hourly_ETa(USUC2_df_processed_2020)\n",
    "USUC2_df_processed_2021_ETa = calculate_hourly_ETa(USUC2_df_processed_2021)\n",
    "USUC2_df_processed_2022_ETa = calculate_hourly_ETa(USUC2_df_processed_2022)\n",
    "USUC2_df_processed_2024_ETa = calculate_hourly_ETa(USUC2_df_processed_2024)\n",
    "\n",
    "USHWB_df_processed_2017_ETa = calculate_hourly_ETa(USHWB_df_processed_2017)\n",
    "\n",
    "# filter dates to only include growing seasons\n",
    "def filter_time_periods(df, time_periods, buffer_days=0):\n",
    "    buffer = pd.Timedelta(days=buffer_days)\n",
    "    return df.loc[pd.Timestamp(time_periods[0][0]) - buffer : pd.Timestamp(time_periods[0][1]) + buffer]\n",
    "\n",
    "USUC1_df_FilteredDates_2019_ETa = filter_time_periods(USUC1_df_processed_2019_ETa, US_UC_growing_season_2019).between_time(\"06:00\", \"18:00\")\n",
    "USUC1_df_FilteredDates_2020_ETa = filter_time_periods(USUC1_df_processed_2020_ETa, US_UC_growing_season_2020).between_time(\"06:00\", \"18:00\")\n",
    "USUC1_df_FilteredDates_2021_ETa = filter_time_periods(USUC1_df_processed_2021_ETa, US_UC_growing_season_2021).between_time(\"06:00\", \"18:00\")\n",
    "USUC1_df_FilteredDates_2022_ETa = filter_time_periods(USUC1_df_processed_2022_ETa, US_UC_growing_season_2022).between_time(\"06:00\", \"18:00\")\n",
    "USUC1_df_FilteredDates_2024_ETa = filter_time_periods(USUC1_df_processed_2024_ETa, US_UC_growing_season_2024).between_time(\"06:00\", \"18:00\")\n",
    "\n",
    "USUC2_df_FilteredDates_2019_ETa = filter_time_periods(USUC2_df_processed_2019_ETa, US_UC_growing_season_2019).between_time(\"06:00\", \"18:00\")\n",
    "USUC2_df_FilteredDates_2020_ETa = filter_time_periods(USUC2_df_processed_2020_ETa, US_UC_growing_season_2020).between_time(\"06:00\", \"18:00\")\n",
    "USUC2_df_FilteredDates_2021_ETa = filter_time_periods(USUC2_df_processed_2021_ETa, US_UC_growing_season_2021).between_time(\"06:00\", \"18:00\")\n",
    "USUC2_df_FilteredDates_2022_ETa = filter_time_periods(USUC2_df_processed_2022_ETa, US_UC_growing_season_2022).between_time(\"06:00\", \"18:00\")\n",
    "USUC2_df_FilteredDates_2024_ETa = filter_time_periods(USUC2_df_processed_2024_ETa, US_UC_growing_season_2024).between_time(\"06:00\", \"18:00\")\n",
    "\n",
    "USHWB_df_FilteredDates_2017_ETa = filter_time_periods(USHWB_df_processed_2017_ETa, US_HWB_growing_season_2017).between_time(\"06:00\", \"18:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cca3d0b-bed9-4144-8eb2-7e98f1f94297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data\n",
    "USUC1_df_FilteredDates_2019_ETa.to_csv('USUC1_df_2019_ETa_MET.csv')\n",
    "USUC1_df_FilteredDates_2020_ETa.to_csv('USUC1_df_2020_ETa_MET.csv')\n",
    "USUC1_df_FilteredDates_2021_ETa.to_csv('USUC1_df_2021_ETa_MET.csv')\n",
    "USUC1_df_FilteredDates_2022_ETa.to_csv('USUC1_df_2022_ETa_MET.csv')\n",
    "USUC1_df_FilteredDates_2024_ETa.to_csv('USUC1_df_2024_ETa_MET.csv')\n",
    "\n",
    "USUC2_df_FilteredDates_2019_ETa.to_csv('USUC2_df_2019_ETa_MET.csv')\n",
    "USUC2_df_FilteredDates_2020_ETa.to_csv('USUC2_df_2020_ETa_MET.csv')\n",
    "USUC2_df_FilteredDates_2021_ETa.to_csv('USUC2_df_2021_ETa_MET.csv')\n",
    "USUC2_df_FilteredDates_2022_ETa.to_csv('USUC2_df_2022_ETa_MET.csv')\n",
    "USUC2_df_FilteredDates_2024_ETa.to_csv('USUC2_df_2024_ETa_MET.csv')\n",
    "\n",
    "USHWB_df_FilteredDates_2017_ETa.to_csv('USHWB_df_2017_ETa_MET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2521465-568c-42da-929e-7ddb3c117715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_1_1_1</th>\n",
       "      <th>RH_1_1_1</th>\n",
       "      <th>SW_IN_1_1_1</th>\n",
       "      <th>LW_IN_1_1_1</th>\n",
       "      <th>WS</th>\n",
       "      <th>PA</th>\n",
       "      <th>P_RAIN_1_1_1</th>\n",
       "      <th>ETa_corr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP_START</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-05-25 06:00:00</th>\n",
       "      <td>12.78950</td>\n",
       "      <td>90.62105</td>\n",
       "      <td>200.71850</td>\n",
       "      <td>298.9905</td>\n",
       "      <td>0.730552</td>\n",
       "      <td>97.27110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-25 07:00:00</th>\n",
       "      <td>16.86500</td>\n",
       "      <td>75.17220</td>\n",
       "      <td>472.17500</td>\n",
       "      <td>301.7510</td>\n",
       "      <td>0.928916</td>\n",
       "      <td>97.32435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-25 08:00:00</th>\n",
       "      <td>20.05490</td>\n",
       "      <td>63.77765</td>\n",
       "      <td>664.41800</td>\n",
       "      <td>315.9345</td>\n",
       "      <td>2.121480</td>\n",
       "      <td>97.32270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-25 09:00:00</th>\n",
       "      <td>22.69410</td>\n",
       "      <td>53.55450</td>\n",
       "      <td>832.10050</td>\n",
       "      <td>326.3645</td>\n",
       "      <td>2.397565</td>\n",
       "      <td>97.27545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-25 10:00:00</th>\n",
       "      <td>24.55185</td>\n",
       "      <td>49.56075</td>\n",
       "      <td>895.99800</td>\n",
       "      <td>342.3230</td>\n",
       "      <td>2.031015</td>\n",
       "      <td>97.26305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-07 14:00:00</th>\n",
       "      <td>15.47765</td>\n",
       "      <td>60.00250</td>\n",
       "      <td>127.55050</td>\n",
       "      <td>361.0270</td>\n",
       "      <td>2.185330</td>\n",
       "      <td>97.39815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-07 15:00:00</th>\n",
       "      <td>15.45550</td>\n",
       "      <td>61.27460</td>\n",
       "      <td>195.20350</td>\n",
       "      <td>345.7030</td>\n",
       "      <td>1.958875</td>\n",
       "      <td>97.38885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-07 16:00:00</th>\n",
       "      <td>14.72385</td>\n",
       "      <td>64.41770</td>\n",
       "      <td>63.08920</td>\n",
       "      <td>347.2620</td>\n",
       "      <td>2.075280</td>\n",
       "      <td>97.39415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-07 17:00:00</th>\n",
       "      <td>13.73385</td>\n",
       "      <td>67.57690</td>\n",
       "      <td>9.41810</td>\n",
       "      <td>349.0200</td>\n",
       "      <td>1.710015</td>\n",
       "      <td>97.41740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-07 18:00:00</th>\n",
       "      <td>12.50480</td>\n",
       "      <td>73.10285</td>\n",
       "      <td>-3.67327</td>\n",
       "      <td>304.1900</td>\n",
       "      <td>1.350885</td>\n",
       "      <td>97.44500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TA_1_1_1  RH_1_1_1  SW_IN_1_1_1  LW_IN_1_1_1        WS  \\\n",
       "TIMESTAMP_START                                                               \n",
       "2024-05-25 06:00:00  12.78950  90.62105    200.71850     298.9905  0.730552   \n",
       "2024-05-25 07:00:00  16.86500  75.17220    472.17500     301.7510  0.928916   \n",
       "2024-05-25 08:00:00  20.05490  63.77765    664.41800     315.9345  2.121480   \n",
       "2024-05-25 09:00:00  22.69410  53.55450    832.10050     326.3645  2.397565   \n",
       "2024-05-25 10:00:00  24.55185  49.56075    895.99800     342.3230  2.031015   \n",
       "...                       ...       ...          ...          ...       ...   \n",
       "2024-10-07 14:00:00  15.47765  60.00250    127.55050     361.0270  2.185330   \n",
       "2024-10-07 15:00:00  15.45550  61.27460    195.20350     345.7030  1.958875   \n",
       "2024-10-07 16:00:00  14.72385  64.41770     63.08920     347.2620  2.075280   \n",
       "2024-10-07 17:00:00  13.73385  67.57690      9.41810     349.0200  1.710015   \n",
       "2024-10-07 18:00:00  12.50480  73.10285     -3.67327     304.1900  1.350885   \n",
       "\n",
       "                           PA  P_RAIN_1_1_1  ETa_corr  \n",
       "TIMESTAMP_START                                        \n",
       "2024-05-25 06:00:00  97.27110           0.0       NaN  \n",
       "2024-05-25 07:00:00  97.32435           0.0  0.208709  \n",
       "2024-05-25 08:00:00  97.32270           0.0  0.185662  \n",
       "2024-05-25 09:00:00  97.27545           0.0  0.290137  \n",
       "2024-05-25 10:00:00  97.26305           0.0  0.235336  \n",
       "...                       ...           ...       ...  \n",
       "2024-10-07 14:00:00  97.39815           0.0  0.166160  \n",
       "2024-10-07 15:00:00  97.38885           0.0  0.138292  \n",
       "2024-10-07 16:00:00  97.39415           0.0  0.081489  \n",
       "2024-10-07 17:00:00  97.41740           0.0  0.084046  \n",
       "2024-10-07 18:00:00  97.44500           0.0  0.031365  \n",
       "\n",
       "[1768 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USUC1_df_FilteredDates_2024_ETa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa6e806",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
